{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datatypes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    200\n",
       "int64        1\n",
       "object       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "50%        -2.819550  \n",
       "max        28.500700  \n",
       "\n",
       "[6 rows x 201 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide features, target and id_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features (200000, 200)\n",
      "target (200000,)\n",
      "id_code (200000,)\n",
      "Wall time: 206 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = df.drop(['ID_code', 'target'], axis=1) #np.array(df)[:,2:]\n",
    "target = df[\"target\"] #np.array(df[\"target\"]).reshape(-1, 1)\n",
    "id_code = df[\"ID_code\"] #np.array(df[\"ID_code\"]).reshape(-1, 1)\n",
    "\n",
    "print(\"features\", features.shape)\n",
    "print(\"target\", target.shape)\n",
    "print(\"id_code\", id_code.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    89.951\n",
       "1    10.049\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].value_counts()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data is imbalanced.** This means that metric _accuracy_ means very little here since we have a _classification problem_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate unique values for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name amount percentage\n",
      "1     target      2        0.0\n",
      "70    var_68    451      0.002\n",
      "93    var_91   7962       0.04\n",
      "110  var_108   8525      0.043\n",
      "105  var_103   9376      0.047\n",
      "        name  amount percentage\n",
      "63    var_61  159369      0.797\n",
      "76    var_74  161058      0.805\n",
      "119  var_117  164469      0.822\n",
      "47    var_45  169968       0.85\n",
      "0    ID_code  200000        1.0\n",
      "Wall time: 3.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "column_names = df.columns\n",
    "\n",
    "temp = np.empty((0,3), str)\n",
    "\n",
    "for column in column_names:\n",
    "    cnt = len(df[column].unique())\n",
    "    pct = round(len(df[column].unique())/df.shape[0], 3)\n",
    "    app = [[column, cnt, pct]]\n",
    "    temp = np.concatenate((temp, app), axis=0)\n",
    "    \n",
    "column_df = pd.DataFrame(temp, columns=[\"name\", \"amount\", \"percentage\"])\n",
    "\n",
    "print(column_df.sort_values([\"percentage\"], ascending=True).head(5))\n",
    "print(column_df.sort_values([\"percentage\"], ascending=True).tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"background-color: black;height: 5.0px;\"/>\n",
    "# Prepare train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_high_density = ['var_139', 'var_76', 'var_149', 'var_21', 'var_184', 'var_174',\n",
    "       'var_80', 'var_45', 'var_40', 'var_90', 'var_26', 'var_48',\n",
    "       'var_118', 'var_18', 'var_172', 'var_67', 'var_70', 'var_107',\n",
    "       'var_86', 'var_147', 'var_44', 'var_74', 'var_165', 'var_199',\n",
    "       'var_13', 'var_190', 'var_173', 'var_110', 'var_123', 'var_137',\n",
    "       'var_5', 'var_49', 'var_167', 'var_75', 'var_154', 'var_164',\n",
    "       'var_122', 'var_109', 'var_155', 'var_135', 'var_170', 'var_51',\n",
    "       'var_1', 'var_87', 'var_141', 'var_33', 'var_82', 'var_97',\n",
    "       'var_92', 'var_35', 'var_81', 'var_157', 'var_22', 'var_187',\n",
    "       'var_178', 'var_83', 'var_163', 'var_180', 'var_146', 'var_102',\n",
    "       'var_198', 'var_0', 'var_2', 'var_52', 'var_191', 'var_179',\n",
    "       'var_89', 'var_11', 'var_54', 'var_188', 'var_115', 'var_120',\n",
    "       'var_196', 'var_119', 'var_94', 'var_56', 'var_127', 'var_36',\n",
    "       'var_145', 'var_20', 'var_142', 'var_151', 'var_24', 'var_99',\n",
    "       'var_134', 'var_58', 'var_177', 'var_55', 'var_186', 'var_78',\n",
    "       'var_85', 'var_47', 'var_19', 'var_128', 'var_61', 'var_138',\n",
    "       'var_171', 'var_84', 'var_32', 'var_140', 'var_193', 'var_194',\n",
    "       'var_77', 'var_121', 'var_8', 'var_150', 'var_175', 'var_192',\n",
    "       'var_182', 'var_113', 'var_159', 'var_106', 'var_176', 'var_160',\n",
    "       'var_6', 'var_31', 'var_104', 'var_72', 'var_9', 'var_88',\n",
    "       'var_73', 'var_63', 'var_53', 'var_162', 'var_101', 'var_168',\n",
    "       'var_65', 'var_195', 'var_116', 'var_132', 'var_112', 'var_117',\n",
    "       'var_136', 'var_197', 'var_69', 'var_143', 'var_158', 'var_62',\n",
    "       'var_111', 'var_152', 'var_34', 'var_114', 'var_96', 'var_130',\n",
    "       'var_129', 'var_183', 'var_95', 'var_60', 'var_66', 'var_16',\n",
    "       'var_166', 'var_156', 'var_3', 'var_100', 'var_64', 'var_144',\n",
    "       'var_105', 'var_39', 'var_169', 'var_46', 'var_93', 'var_28',\n",
    "       'var_4', 'var_181', 'var_37', 'var_133', 'var_12', 'var_131',\n",
    "       'var_23', 'var_7', 'var_124', 'var_10', 'var_57', 'var_153',\n",
    "       'var_14', 'var_29', 'var_189', 'var_79', 'var_43', 'var_59',\n",
    "       'var_71', 'var_108', 'var_148', 'var_125', 'var_50', 'var_91',\n",
    "       'var_41', 'var_42', 'var_17', 'var_30', 'var_15', 'var_126',\n",
    "       'var_25', 'var_161', 'var_38', 'var_98', 'var_27', 'var_185',\n",
    "       'var_103', 'var_68']\n",
    "\n",
    "feature_high_density = feature_high_density[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (144000, 200)\n",
      "Shape of x_test: (40000, 200)\n",
      "Shape of x_val: (16000, 200)\n",
      "Shape of y_train: (144000, 1)\n",
      "Shape of y_test: (40000, 1)\n",
      "Shape of y_val: (16000, 1)\n",
      "Wall time: 763 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=15, stratify=target)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(features[feature_high_density], target, test_size=0.2, random_state=15, stratify=target)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=15, stratify=y_train)\n",
    "\n",
    "x_train = np.float64(x_train)\n",
    "x_val = np.float64(x_val)\n",
    "x_test = np.float64(x_test)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_val = np.array(y_val).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of x_val:\", x_val.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 366 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 511 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"background-color: black;height: 5.0px;\"/>\n",
    "# Build the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_class(x, threshold=0.5):\n",
    "    return np.where(x > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.constraints import unit_norm, max_norm\n",
    "from tensorflow.keras import regularizers, initializers\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accepted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input dimension: 200\n",
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 0.4305 - val_loss: 0.3827\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3425 - val_loss: 0.3378\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.3301 - val_loss: 0.3243\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.3240 - val_loss: 0.3225\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.3222 - val_loss: 0.3215\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.3211 - val_loss: 0.3202\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.3197 - val_loss: 0.3188\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.3184 - val_loss: 0.3174\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.3169 - val_loss: 0.3159\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.3154 - val_loss: 0.3144\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.3137 - val_loss: 0.3125\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.3119 - val_loss: 0.3106\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.3099 - val_loss: 0.3086\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.3078 - val_loss: 0.3062\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.3054 - val_loss: 0.3036\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.3027 - val_loss: 0.3009\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.3000 - val_loss: 0.2980\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.2969 - val_loss: 0.2947\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.2936 - val_loss: 0.2913\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.2901 - val_loss: 0.2877\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.2865 - val_loss: 0.2838\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.2826 - val_loss: 0.2799\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.2787 - val_loss: 0.2759\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.2747 - val_loss: 0.2718\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.2706 - val_loss: 0.2677\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.2667 - val_loss: 0.2638\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.2629 - val_loss: 0.2601\n",
      "Epoch 28/100\n",
      " - 3s - loss: 0.2593 - val_loss: 0.2566\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.2557 - val_loss: 0.2532\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.2526 - val_loss: 0.2503\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.2495 - val_loss: 0.2475\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.2469 - val_loss: 0.2450\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.2445 - val_loss: 0.2430\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.2424 - val_loss: 0.2409\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.2404 - val_loss: 0.2394\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.2390 - val_loss: 0.2383\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.2379 - val_loss: 0.2367\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.2367 - val_loss: 0.2360\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.2358 - val_loss: 0.2351\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.2348 - val_loss: 0.2346\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.2342 - val_loss: 0.2341\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.2335 - val_loss: 0.2336\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.2337 - val_loss: 0.2336\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.2333 - val_loss: 0.2338\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.2327 - val_loss: 0.2327\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.2324 - val_loss: 0.2327\n",
      "Epoch 47/100\n",
      " - 2s - loss: 0.2321 - val_loss: 0.2326\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.2320 - val_loss: 0.2323\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.2318 - val_loss: 0.2324\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.2316 - val_loss: 0.2327\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.2319 - val_loss: 0.2323\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.2318 - val_loss: 0.2323\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.2316 - val_loss: 0.2324\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.2312 - val_loss: 0.2320\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.2313 - val_loss: 0.2319\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.2311 - val_loss: 0.2319\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.2312 - val_loss: 0.2319\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.2311 - val_loss: 0.2318\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.2314 - val_loss: 0.2322\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.2313 - val_loss: 0.2318\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.2313 - val_loss: 0.2324\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.2313 - val_loss: 0.2321\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.2310 - val_loss: 0.2318\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.2313 - val_loss: 0.2324\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.2312 - val_loss: 0.2323\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.2312 - val_loss: 0.2323\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.2311 - val_loss: 0.2318\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.2309 - val_loss: 0.2319\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.2310 - val_loss: 0.2320\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.2308 - val_loss: 0.2320\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.2307 - val_loss: 0.2317\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.2307 - val_loss: 0.2317\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2320\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.2308 - val_loss: 0.2317\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.2307 - val_loss: 0.2321\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.2307 - val_loss: 0.2316\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2316\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2319\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2316\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.2309 - val_loss: 0.2316\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.2308 - val_loss: 0.2316\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.2307 - val_loss: 0.2320\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.2307 - val_loss: 0.2317\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2316\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2320\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.2307 - val_loss: 0.2323\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2316\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2319\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.2309 - val_loss: 0.2317\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2316\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.2304 - val_loss: 0.2315\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.2305 - val_loss: 0.2315\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.2305 - val_loss: 0.2316\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.2308 - val_loss: 0.2322\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.2307 - val_loss: 0.2316\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.2304 - val_loss: 0.2316\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.2304 - val_loss: 0.2316\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.2308 - val_loss: 0.2325\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.2306 - val_loss: 0.2315\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.2304 - val_loss: 0.2315\n",
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Size of input dimension:\", x_train_scaled.shape[1])\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, input_dim=x_train_scaled.shape[1],\n",
    "                #kernel_constraint=unit_norm(),\n",
    "                #kernel_regularizer=regularizers.l2(0.001),\n",
    "                activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.8)) # 0.2 < dropout < 0.5\n",
    "#model.add(Dense(units=128, input_dim=x_train_scaled.shape[1],\n",
    "                #kernel_constraint=unit_norm(),\n",
    "                #kernel_regularizer=regularizers.l2(0.001),\n",
    "#                activation=\"tanh\"))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(rate=0.5)) # 0.2 < dropout < 0.5\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "#model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[auroc])\n",
    "\n",
    "history = model.fit(x_train_scaled, y_train, validation_data=(x_val_scaled, y_val),\n",
    "                    epochs=100,\n",
    "                    batch_size=int(x_train_scaled.shape[0]/10),\n",
    "                    #batch_size=2048,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 80)                16080     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 19,361\n",
      "Trainable params: 19,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 24us/step\n",
      "Metric loss : 0.2336\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test_scaled, y_test)\n",
    "print(\"Metric\", model.metrics_names[0],\":\",str(round(result, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability    float64\n",
      "predicted      float64\n",
      "target         float64\n",
      "dtype: object\n",
      "0.0    96.14\n",
      "1.0     3.86\n",
      "Name: predicted, dtype: float64\n",
      "0.0    89.95\n",
      "1.0    10.05\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>predicted</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   probability  predicted  target\n",
       "0     0.100877        0.0     0.0\n",
       "1     0.014841        0.0     0.0\n",
       "2     0.016622        0.0     0.0\n",
       "3     0.000785        0.0     0.0\n",
       "4     0.019304        0.0     0.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_x_test =  model.predict(x_test_scaled)\n",
    "res_df = pd.DataFrame(np.concatenate((probability_x_test, prob_to_class(probability_x_test, 0.5), y_test), axis=1), columns=[\"probability\", \"predicted\", \"target\"])\n",
    "print(res_df.dtypes)\n",
    "print(res_df[\"predicted\"].value_counts()/res_df.shape[0]*100)\n",
    "print(res_df[\"target\"].value_counts()/res_df.shape[0]*100)\n",
    "res_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_loss = np.max(history.history[\"loss\"])\n",
    "min_loss = np.min(history.history[\"val_loss\"]) - 0.25 * np.min(history.history[\"val_loss\"])\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model's Training & Validation loss across epochs\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylim(min_loss, max_loss)\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"background-color: black;height: 5.0px;\"/>\n",
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8595957123775231\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "roc_score = roc_auc_score(y_test, probability_x_test)\n",
    "\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc - 0.857143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"background-color: black;height: 5.0px;\"/>\n",
    "## Submission of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "0  18.2675  2.1337   ...     -2.1556  11.8495  -1.4300   2.4508  13.7112   \n",
       "1  18.6316 -4.4131   ...     10.6165   8.8349   0.9403  10.1282  15.5765   \n",
       "2  20.2537  1.5233   ...     -0.7484  10.9935   1.9803   2.1800  12.9813   \n",
       "3  20.5660  3.3755   ...      9.5702   9.0766   1.6580   3.5813  15.1874   \n",
       "4  10.6048  2.9890   ...      4.2259   9.1723   1.2835   3.3778  19.5542   \n",
       "\n",
       "   var_195  var_196  var_197  var_198  var_199  \n",
       "0   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
       "1   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_features shape (200000, 200)\n",
      "result_df shape (200000, 1)\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_features = test.drop(['ID_code'], axis=1) #np.array(test)[:,1:]\n",
    "result_df = pd.DataFrame(test[\"ID_code\"])\n",
    "\n",
    "print(\"test_features shape\", test_features.shape)\n",
    "print(\"result_df shape\", result_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 508 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_scaled = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.535360</td>\n",
       "      <td>0.897837</td>\n",
       "      <td>0.628717</td>\n",
       "      <td>0.715833</td>\n",
       "      <td>0.548256</td>\n",
       "      <td>0.607399</td>\n",
       "      <td>0.574061</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.601954</td>\n",
       "      <td>0.666409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365097</td>\n",
       "      <td>0.749230</td>\n",
       "      <td>0.195180</td>\n",
       "      <td>0.456168</td>\n",
       "      <td>0.266369</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.566680</td>\n",
       "      <td>0.788006</td>\n",
       "      <td>0.464797</td>\n",
       "      <td>0.447387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.408005</td>\n",
       "      <td>0.641132</td>\n",
       "      <td>0.533050</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.355501</td>\n",
       "      <td>0.574572</td>\n",
       "      <td>0.601977</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>0.276928</td>\n",
       "      <td>0.259747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758807</td>\n",
       "      <td>0.593904</td>\n",
       "      <td>0.389199</td>\n",
       "      <td>0.719905</td>\n",
       "      <td>0.365408</td>\n",
       "      <td>0.601884</td>\n",
       "      <td>0.385026</td>\n",
       "      <td>0.647505</td>\n",
       "      <td>0.650104</td>\n",
       "      <td>0.265418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.254905</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.535820</td>\n",
       "      <td>0.447373</td>\n",
       "      <td>0.852630</td>\n",
       "      <td>0.417628</td>\n",
       "      <td>0.667081</td>\n",
       "      <td>0.571650</td>\n",
       "      <td>0.599619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408475</td>\n",
       "      <td>0.705125</td>\n",
       "      <td>0.474327</td>\n",
       "      <td>0.446866</td>\n",
       "      <td>0.227615</td>\n",
       "      <td>0.775034</td>\n",
       "      <td>0.210427</td>\n",
       "      <td>0.182324</td>\n",
       "      <td>0.688933</td>\n",
       "      <td>0.232704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408357</td>\n",
       "      <td>0.539775</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.500064</td>\n",
       "      <td>0.325182</td>\n",
       "      <td>0.719189</td>\n",
       "      <td>0.424956</td>\n",
       "      <td>0.681060</td>\n",
       "      <td>0.663605</td>\n",
       "      <td>0.472520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726554</td>\n",
       "      <td>0.606357</td>\n",
       "      <td>0.447945</td>\n",
       "      <td>0.495003</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>0.883857</td>\n",
       "      <td>0.553991</td>\n",
       "      <td>0.541227</td>\n",
       "      <td>0.340380</td>\n",
       "      <td>0.514331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567520</td>\n",
       "      <td>0.586569</td>\n",
       "      <td>0.696941</td>\n",
       "      <td>0.588941</td>\n",
       "      <td>0.347404</td>\n",
       "      <td>0.482541</td>\n",
       "      <td>0.739656</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>0.644417</td>\n",
       "      <td>0.427482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561812</td>\n",
       "      <td>0.611288</td>\n",
       "      <td>0.417291</td>\n",
       "      <td>0.488013</td>\n",
       "      <td>0.576606</td>\n",
       "      <td>0.521822</td>\n",
       "      <td>0.270891</td>\n",
       "      <td>0.219809</td>\n",
       "      <td>0.386450</td>\n",
       "      <td>0.440485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.535360  0.897837  0.628717  0.715833  0.548256  0.607399  0.574061   \n",
       "1  0.408005  0.641132  0.533050  0.395056  0.355501  0.574572  0.601977   \n",
       "2  0.254905  0.184314  0.465517  0.535820  0.447373  0.852630  0.417628   \n",
       "3  0.408357  0.539775  0.574667  0.500064  0.325182  0.719189  0.424956   \n",
       "4  0.567520  0.586569  0.696941  0.588941  0.347404  0.482541  0.739656   \n",
       "\n",
       "        7         8         9      ...          190       191       192  \\\n",
       "0  0.578182  0.601954  0.666409    ...     0.365097  0.749230  0.195180   \n",
       "1  0.594479  0.276928  0.259747    ...     0.758807  0.593904  0.389199   \n",
       "2  0.667081  0.571650  0.599619    ...     0.408475  0.705125  0.474327   \n",
       "3  0.681060  0.663605  0.472520    ...     0.726554  0.606357  0.447945   \n",
       "4  0.235211  0.644417  0.427482    ...     0.561812  0.611288  0.417291   \n",
       "\n",
       "        193       194       195       196       197       198       199  \n",
       "0  0.456168  0.266369  0.810571  0.566680  0.788006  0.464797  0.447387  \n",
       "1  0.719905  0.365408  0.601884  0.385026  0.647505  0.650104  0.265418  \n",
       "2  0.446866  0.227615  0.775034  0.210427  0.182324  0.688933  0.232704  \n",
       "3  0.495003  0.344749  0.883857  0.553991  0.541227  0.340380  0.514331  \n",
       "4  0.488013  0.576606  0.521822  0.270891  0.219809  0.386450  0.440485  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_scaled).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert probability to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID_code  target  classification  probability\n",
      "0  test_0     0.2               0          0.1\n",
      "1  test_1     0.3               0          0.2\n",
      "2  test_2     0.0               0          0.0\n",
      "3  test_3     0.2               0          0.3\n",
      "4  test_4     0.1               0          0.0\n",
      "Wall time: 2.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_df['probability'] = np.round(model.predict(test_scaled), 1)\n",
    "result_df['classification'] = prob_to_class(x=result_df['probability'], threshold=0.5)\n",
    "\n",
    "print(result_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    96.9995\n",
       "1     3.0005\n",
       "Name: classification, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['classification'].value_counts()/result_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%Y%m%d_%H%M', t)\n",
    "save_filename = (\"score/nn_result-\" + timestamp + \".csv\")\n",
    "\n",
    "result_df = result_df.rename(columns={'probability': 'target'}) # rename to match submission criteria\n",
    "result_df[['ID_code', 'target']].to_csv(save_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
